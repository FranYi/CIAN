## Cross-Modality Interactive Attention Network for Multispectral Pedestrian Detection

Created by Lu Zhang, Institute of Automation, Chinese Academy of Science.

### Introduction

We propose a novel single-shot multispectral pedestrian detector, called CIAN, that utilizes the cross-modality (e.g., color, and long-wavelength infrared) information in an adaptive way. For more details, please refer to our [paper](https://www.sciencedirect.com/science/article/pii/S1566253518304111).

<p align="left">
<img src="https://github.com/luzhang16/CIAN/blob/master/cian_structure.png" alt="CIAN Structure" width="770px">
</p>
<p align="left">
<img src="https://github.com/luzhang16/CIAN/blob/master/eval_results.png" alt="Evaluation Results on the KAIST" width="770px">
</p>


Evaluation results are now updated on the [improved testing annotations](http://paul.rutgers.edu/~jl1322/multispectral.htm) provided by Liu et al. for a reliable comparison.


### Downloads

**Detection results** are available through [[Google Drive]](https://drive.google.com/open?id=1lMPsD_MuaHtjb8bbxx_KGWggKv87zm9h) and [[BaiduYun]](https://pan.baidu.com/s/10DuqjUkO7sAR57QnXWEb0A). If you have any problem, please feel free to contact me.

### Citing the paper

Please cite our paper in your publications if it helps your research:

```
@article{zhang2019cross,
  title={Cross-modality interactive attention network for multispectral pedestrian detection},
  author={Zhang, Lu and Liu, Zhiyong and Zhang, Shifeng and Yang, Xu and Qiao, Hong and Huang, Kaizhu and Hussain, Amir},
  journal={Information Fusion},
  volume={50},
  pages={20--29},
  year={2019},
  publisher={Elsevier}
}
```